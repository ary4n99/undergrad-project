{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "-qMlcpmuSmwK"
            },
            "outputs": [],
            "source": [
                "import warnings\n",
                "\n",
                "import gym\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "\n",
                "import utils\n",
                "\n",
                "keras = tf.keras\n",
                "\n",
                "from keras.layers import Dense, Input\n",
                "from keras.optimizers import Adam\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "GAME = \"mountain_car_a2c\"\n",
                "VERBOSITY = \"0\"\n",
                "SAVE_FREQUENCY = 25"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "tUkQyIFaSq8M"
            },
            "outputs": [],
            "source": [
                "# Hyperparameters\n",
                "EPISODES = 500\n",
                "LEARNING_RATE = 0.001\n",
                "GAMMA = 0.99"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "CBwZ8nGiSq15"
            },
            "outputs": [],
            "source": [
                "def instantiate_model(env):\n",
                "    input = Input(shape=(env.observation_space.shape))\n",
                "\n",
                "    dense1 = Dense(32, activation=\"relu\")(input)\n",
                "    dense2 = Dense(64, activation=\"relu\")(dense1)\n",
                "    output = Dense(env.action_space.n)(dense2)\n",
                "    actor = keras.Model(inputs=input, outputs=output)\n",
                "\n",
                "    dense1 = Dense(32, activation=\"relu\")(input)\n",
                "    output = Dense(1)(dense1)\n",
                "    critic = keras.Model(inputs=input, outputs=output)\n",
                "\n",
                "    return actor, critic\n",
                "\n",
                "\n",
                "def take_action(env, action):\n",
                "    next_state, reward, done, _ = env.step(action)\n",
                "    return next_state, reward, done\n",
                "\n",
                "\n",
                "def shape_reward(state, next_state, reward):\n",
                "    return reward + 300 * (abs(next_state[1]) - abs(state[1]))\n",
                "\n",
                "\n",
                "def update_weights(actor, critic, optimizer, tape, state, next_state, reward,\n",
                "                   done, action_log_prob):\n",
                "    advantage = reward + (1 - done) * GAMMA * critic(\n",
                "        np.expand_dims(next_state, axis=0)) - critic(\n",
                "            np.expand_dims(state, axis=0))\n",
                "\n",
                "    critic_loss = tf.math.pow(advantage, 2)\n",
                "    grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
                "    optimizer.apply_gradients(zip(grads, critic.trainable_variables))\n",
                "\n",
                "    actor_loss = -action_log_prob * advantage\n",
                "    grads = tape.gradient(actor_loss, actor.trainable_variables)\n",
                "    optimizer.apply_gradients(zip(grads, actor.trainable_variables))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "EH9723DLQXEd"
            },
            "outputs": [],
            "source": [
                "env = gym.make(\"MountainCar-v0\", new_step_api=False)\n",
                "\n",
                "actor, critic = instantiate_model(env)\n",
                "\n",
                "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
                "\n",
                "reward_history = []\n",
                "\n",
                "# Training\n",
                "for episode in range(EPISODES + 1):\n",
                "    state = env.reset()\n",
                "    episode_reward = 0\n",
                "    done = False\n",
                "\n",
                "    # Episode loop\n",
                "    with tf.GradientTape(persistent=True) as tape:\n",
                "        while not done:\n",
                "            action_logits = actor(np.expand_dims(state, axis=0))\n",
                "            action = tf.random.categorical(action_logits, 1)[0, 0]\n",
                "            action_probs = tf.nn.softmax(action_logits)\n",
                "\n",
                "            next_state, reward, done = take_action(env, int(action))\n",
                "            reward = shape_reward(state, next_state, reward)\n",
                "            episode_reward += reward\n",
                "\n",
                "            action_log_prob = tf.math.log(action_probs[0, action])\n",
                "\n",
                "            update_weights(actor, critic, optimizer, tape, state, next_state,\n",
                "                           reward, done, action_log_prob)\n",
                "\n",
                "            state = next_state\n",
                "\n",
                "    reward_history.append(episode_reward)\n",
                "\n",
                "    utils.save_progress(actor, reward_history, episode + 1, SAVE_FREQUENCY,\n",
                "                        GAME)\n",
                "\n",
                "    utils.log(episode, episode_reward)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "private_outputs": true,
            "provenance": []
        },
        "gpuClass": "standard",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.16"
        },
        "vscode": {
            "interpreter": {
                "hash": "b946e2faa49f4674d4dbe235d6e8a6770d62cc3857e24103415cecb3f0034c27"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
